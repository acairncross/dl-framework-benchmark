{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b099ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import grad, jit, vmap, random, lax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cfa733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3721109   0.26423115 -0.18252768 -0.7368197  -0.44030377 -0.1521442\n",
      " -0.67135346 -0.5908641   0.73168886  0.5673026 ]\n"
     ]
    }
   ],
   "source": [
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "    return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "x = random.normal(key, (10,))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1842afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import register_pytree_node_class\n",
    "\n",
    "@register_pytree_node_class\n",
    "@dataclass\n",
    "class LstmParams:\n",
    "    w_ih: np.ndarray\n",
    "    w_hh: np.ndarray\n",
    "    b_ih: np.ndarray\n",
    "    b_hh: np.ndarray\n",
    "        \n",
    "    def tree_flatten(self):\n",
    "        children = self.w_ih, self.w_hh, self.b_ih, self.b_hh\n",
    "        aux_data = None\n",
    "        return children, aux_data\n",
    "    \n",
    "    @classmethod\n",
    "    def tree_unflatten(cls, aux_data, children):\n",
    "        return cls(*children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a3aacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(params, xs, h_0, c_0):\n",
    "    final_state, output = lax.scan(partial(lstm_step, params), (h_0, c_0), xs)\n",
    "    return output\n",
    "\n",
    "def lstm_step(params, state, xs):\n",
    "    \n",
    "    h_0, c_0 = state\n",
    "    \n",
    "    gates = params.w_ih @ xs + params.b_ih + params.w_hh @ h_0 + params.b_hh\n",
    "    in_gate, forget_gate, cell_gate, out_gate = jnp.split(gates, 4)\n",
    "    \n",
    "    cy = (forget_gate * c_0) + (in_gate * cell_gate)\n",
    "    hy = out_gate * jax.nn.tanh(cy)\n",
    "    \n",
    "    return (hy, cy), hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9f9f8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 141 ms, sys: 26.3 ms, total: 167 ms\n",
      "Wall time: 277 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0., 0., 0., ..., 0., 0., 0.],\n",
       "             [0., 0., 0., ..., 0., 0., 0.],\n",
       "             [0., 0., 0., ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0., ..., 0., 0., 0.],\n",
       "             [0., 0., 0., ..., 0., 0., 0.],\n",
       "             [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "input_size = 128\n",
    "hidden_size = 128\n",
    "lstm_model_jit = jit(lstm_model)\n",
    "lstm_model_jit(\n",
    "    LstmParams(\n",
    "        np.zeros((4 * hidden_size, input_size)),\n",
    "        np.zeros((4 * hidden_size, hidden_size)),\n",
    "        np.zeros((4 * hidden_size,)),\n",
    "        np.zeros((4 * hidden_size,)),\n",
    "    ),\n",
    "    np.zeros((1000, input_size,)),\n",
    "    np.zeros((hidden_size,)),\n",
    "    np.zeros((hidden_size,)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "26f1904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module @jit_lstm_model.52 {\n",
      "  func.func public @main(%arg0: tensor<4096x1024xf32>, %arg1: tensor<4096xf32>, %arg2: tensor<4096x1024xf32>, %arg3: tensor<4096xf32>, %arg4: tensor<1000x1024xf32>, %arg5: tensor<1024xf32>, %arg6: tensor<1024xf32>) -> tensor<1000x1024xf32> {\n",
      "    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>\n",
      "    %1 = \"mhlo.broadcast_in_dim\"(%0) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<1000x1024xf32>\n",
      "    %2 = mhlo.constant dense<0> : tensor<i32>\n",
      "    %3:9 = mhlo.while(%iterArg = %arg4, %iterArg_0 = %arg0, %iterArg_1 = %arg1, %iterArg_2 = %arg2, %iterArg_3 = %arg3, %iterArg_4 = %2, %iterArg_5 = %arg5, %iterArg_6 = %arg6, %iterArg_7 = %1) : tensor<1000x1024xf32>, tensor<4096x1024xf32>, tensor<4096xf32>, tensor<4096x1024xf32>, tensor<4096xf32>, tensor<i32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1000x1024xf32>\n",
      "     cond {\n",
      "      %4 = mhlo.constant dense<1000> : tensor<i32>\n",
      "      %5 = \"mhlo.compare\"(%iterArg_4, %4) {compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction LT>} : (tensor<i32>, tensor<i32>) -> tensor<i1>\n",
      "      \"mhlo.return\"(%5) : (tensor<i1>) -> ()\n",
      "    } do {\n",
      "      %4 = mhlo.constant dense<0> : tensor<i32>\n",
      "      %5 = \"mhlo.compare\"(%iterArg_4, %4) {compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction LT>} : (tensor<i32>, tensor<i32>) -> tensor<i1>\n",
      "      %6 = mhlo.convert %iterArg_4 : tensor<i32>\n",
      "      %7 = mhlo.constant dense<1000> : tensor<i32>\n",
      "      %8 = mhlo.add %6, %7 : tensor<i32>\n",
      "      %9 = \"mhlo.select\"(%5, %8, %iterArg_4) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\n",
      "      %10 = mhlo.constant dense<0> : tensor<i32>\n",
      "      %11 = mhlo.constant dense<0> : tensor<i32>\n",
      "      %12 = \"mhlo.compare\"(%10, %11) {compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction LT>} : (tensor<i32>, tensor<i32>) -> tensor<i1>\n",
      "      %13 = mhlo.constant dense<0> : tensor<i32>\n",
      "      %14 = mhlo.constant dense<1024> : tensor<i32>\n",
      "      %15 = mhlo.add %13, %14 : tensor<i32>\n",
      "      %16 = mhlo.constant dense<0> : tensor<i32>\n",
      "      %17 = \"mhlo.select\"(%12, %15, %16) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\n",
      "      %18 = \"mhlo.dynamic_slice\"(%iterArg, %9, %17) {slice_sizes = dense<[1, 1024]> : tensor<2xi64>} : (tensor<1000x1024xf32>, tensor<i32>, tensor<i32>) -> tensor<1x1024xf32>\n",
      "      %19 = \"mhlo.reshape\"(%18) : (tensor<1x1024xf32>) -> tensor<1024xf32>\n",
      "      %20 = \"mhlo.dot_general\"(%iterArg_0, %19) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<4096x1024xf32>, tensor<1024xf32>) -> tensor<4096xf32>\n",
      "      %21 = mhlo.add %20, %iterArg_1 : tensor<4096xf32>\n",
      "      %22 = \"mhlo.dot_general\"(%iterArg_2, %iterArg_5) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<4096x1024xf32>, tensor<1024xf32>) -> tensor<4096xf32>\n",
      "      %23 = mhlo.add %21, %22 : tensor<4096xf32>\n",
      "      %24 = mhlo.add %23, %iterArg_3 : tensor<4096xf32>\n",
      "      %25 = \"mhlo.slice\"(%24) {limit_indices = dense<1024> : tensor<1xi64>, start_indices = dense<0> : tensor<1xi64>, strides = dense<1> : tensor<1xi64>} : (tensor<4096xf32>) -> tensor<1024xf32>\n",
      "      %26 = \"mhlo.slice\"(%24) {limit_indices = dense<2048> : tensor<1xi64>, start_indices = dense<1024> : tensor<1xi64>, strides = dense<1> : tensor<1xi64>} : (tensor<4096xf32>) -> tensor<1024xf32>\n",
      "      %27 = \"mhlo.slice\"(%24) {limit_indices = dense<3072> : tensor<1xi64>, start_indices = dense<2048> : tensor<1xi64>, strides = dense<1> : tensor<1xi64>} : (tensor<4096xf32>) -> tensor<1024xf32>\n",
      "      %28 = \"mhlo.slice\"(%24) {limit_indices = dense<4096> : tensor<1xi64>, start_indices = dense<3072> : tensor<1xi64>, strides = dense<1> : tensor<1xi64>} : (tensor<4096xf32>) -> tensor<1024xf32>\n",
      "      %29 = mhlo.multiply %26, %iterArg_6 : tensor<1024xf32>\n",
      "      %30 = mhlo.multiply %25, %27 : tensor<1024xf32>\n",
      "      %31 = mhlo.add %29, %30 : tensor<1024xf32>\n",
      "      %32 = mhlo.tanh %31 : tensor<1024xf32>\n",
      "      %33 = mhlo.multiply %28, %32 : tensor<1024xf32>\n",
      "      %34 = \"mhlo.broadcast_in_dim\"(%33) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<1024xf32>) -> tensor<1x1024xf32>\n",
      "      %35 = mhlo.constant dense<0> : tensor<i32>\n",
      "      %36 = \"mhlo.compare\"(%iterArg_4, %35) {compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction LT>} : (tensor<i32>, tensor<i32>) -> tensor<i1>\n",
      "      %37 = mhlo.convert %iterArg_4 : tensor<i32>\n",
      "      %38 = mhlo.constant dense<1000> : tensor<i32>\n",
      "      %39 = mhlo.add %37, %38 : tensor<i32>\n",
      "      %40 = \"mhlo.select\"(%36, %39, %iterArg_4) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\n",
      "      %41 = mhlo.constant dense<0> : tensor<i32>\n",
      "      %42 = mhlo.constant dense<0> : tensor<i32>\n",
      "      %43 = \"mhlo.compare\"(%41, %42) {compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction LT>} : (tensor<i32>, tensor<i32>) -> tensor<i1>\n",
      "      %44 = mhlo.constant dense<0> : tensor<i32>\n",
      "      %45 = mhlo.constant dense<1024> : tensor<i32>\n",
      "      %46 = mhlo.add %44, %45 : tensor<i32>\n",
      "      %47 = mhlo.constant dense<0> : tensor<i32>\n",
      "      %48 = \"mhlo.select\"(%43, %46, %47) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\n",
      "      %49 = \"mhlo.dynamic_update_slice\"(%iterArg_7, %34, %40, %48) : (tensor<1000x1024xf32>, tensor<1x1024xf32>, tensor<i32>, tensor<i32>) -> tensor<1000x1024xf32>\n",
      "      %50 = mhlo.constant dense<1> : tensor<i32>\n",
      "      %51 = mhlo.add %iterArg_4, %50 : tensor<i32>\n",
      "      \"mhlo.return\"(%iterArg, %iterArg_0, %iterArg_1, %iterArg_2, %iterArg_3, %51, %33, %31, %49) : (tensor<1000x1024xf32>, tensor<4096x1024xf32>, tensor<4096xf32>, tensor<4096x1024xf32>, tensor<4096xf32>, tensor<i32>, tensor<1024xf32>, tensor<1024xf32>, tensor<1000x1024xf32>) -> ()\n",
      "    }\n",
      "    return %3#8 : tensor<1000x1024xf32>\n",
      "  }\n",
      "}\n",
      "\n",
      "CPU times: user 63 ms, sys: 1.74 ms, total: 64.8 ms\n",
      "Wall time: 64.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(lstm_model_jit.lower(\n",
    "    (\n",
    "        np.zeros((4 * hidden_size, input_size)),\n",
    "        np.zeros((4 * hidden_size,)),\n",
    "        np.zeros((4 * hidden_size, hidden_size)),\n",
    "        np.zeros((4 * hidden_size,)),\n",
    "    ),\n",
    "    np.zeros((1000, input_size,)),\n",
    "    np.zeros((hidden_size,)),\n",
    "    np.zeros((hidden_size,)),\n",
    ").as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7272dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = CustomLSTMCell(input_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        h, c = torch.zeros(self.hidden_size), torch.zeros(self.hidden_size)\n",
    "        outputs = []\n",
    "        for i in range(len(input)):\n",
    "            h, c = self.cell(input[i], (h, c))\n",
    "            outputs.append(h)\n",
    "            \n",
    "        return outputs, (h, c)\n",
    "\n",
    "class CustomLSTMCell(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_ih = torch.nn.Parameter(torch.randn(4 * hidden_size, input_size))\n",
    "        self.weight_hh = torch.nn.Parameter(torch.randn(4 * hidden_size, hidden_size))\n",
    "        self.bias_ih = torch.nn.Parameter(torch.randn(4 * hidden_size))\n",
    "        self.bias_hh = torch.nn.Parameter(torch.randn(4 * hidden_size))\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        # type: (Tensor, Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tuple[Tensor, Tensor]]\n",
    "        hx, cx = state\n",
    "        gates = (input @ self.weight_ih.t() + self.bias_ih +\n",
    "                 hx @ self.weight_hh.t() + self.bias_hh)\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 0)\n",
    "\n",
    "        ingate = torch.sigmoid(ingate)\n",
    "        forgetgate = torch.sigmoid(forgetgate)\n",
    "        cellgate = torch.tanh(cellgate)\n",
    "        outgate = torch.sigmoid(outgate)\n",
    "\n",
    "        cy = (forgetgate * cx) + (ingate * cellgate)\n",
    "        hy = outgate * torch.tanh(cy)\n",
    "\n",
    "        return hy, cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "10ca2647",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_lstm = CustomLSTM(128, 128)\n",
    "t = torch.zeros(1000, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "11055856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 286 ms, sys: 1.41 ms, total: 287 ms\n",
      "Wall time: 156 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    torch_lstm(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "lax.scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ef3366b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96589488,  0.30303295,  0.74763393, ..., -0.6795796 ,\n",
       "         0.06711103,  1.17431941],\n",
       "       [ 0.70892449,  0.31808199, -0.82909577, ...,  1.20363463,\n",
       "         0.46466613,  1.98741418],\n",
       "       [ 0.5813831 ,  0.04676802,  1.58081992, ..., -0.71274007,\n",
       "        -1.6727985 ,  0.24868153],\n",
       "       ...,\n",
       "       [-0.31201267,  0.61315431,  2.16878743, ..., -0.71575788,\n",
       "        -0.196202  , -0.81780193],\n",
       "       [ 0.27412789, -2.05271653, -1.15464317, ..., -0.95800908,\n",
       "        -2.38512656,  0.69364098],\n",
       "       [-1.34154884, -0.11968709, -1.59875441, ..., -1.50942542,\n",
       "        -0.49023361,  0.38057436]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3767745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = (\n",
    "    np.random.normal(size=(64, 64)),\n",
    "    np.random.normal(size=(64,)),\n",
    ")\n",
    "xs = np.random.normal(size=(64,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09d07444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ lambda ; a:f32[64,64] b:f32[64] c:f32[64]. let\n",
       "    d:f32[64] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a c\n",
       "    e:f32[64] = add d b\n",
       "    f:f32[64] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a e\n",
       "    g:f32[64] = add f b\n",
       "    h:f32[64] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a g\n",
       "    i:f32[64] = add h b\n",
       "    j:f32[64] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a i\n",
       "    k:f32[64] = add j b\n",
       "    l:f32[64] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a k\n",
       "    m:f32[64] = add l b\n",
       "    n:f32[64] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a m\n",
       "    o:f32[64] = add n b\n",
       "    p:f32[64] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a o\n",
       "    q:f32[64] = add p b\n",
       "    r:f32[64] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a q\n",
       "    s:f32[64] = add r b\n",
       "    t:f32[64] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a s\n",
       "    u:f32[64] = add t b\n",
       "    v:f32[64] = dot_general[\n",
       "      dimension_numbers=(((1,), (0,)), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a u\n",
       "    w:f32[64] = add v b\n",
       "  in (w,) }"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.make_jaxpr(rnn_model)(theta, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1534b294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module @jit_rnn_model.39 {\n",
      "  func.func public @main(%arg0: tensor<64x64xf32>, %arg1: tensor<64xf32>, %arg2: tensor<64xf32>) -> tensor<64xf32> {\n",
      "    %0 = \"mhlo.dot_general\"(%arg0, %arg2) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<64x64xf32>, tensor<64xf32>) -> tensor<64xf32>\n",
      "    %1 = mhlo.add %0, %arg1 : tensor<64xf32>\n",
      "    %2 = \"mhlo.dot_general\"(%arg0, %1) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<64x64xf32>, tensor<64xf32>) -> tensor<64xf32>\n",
      "    %3 = mhlo.add %2, %arg1 : tensor<64xf32>\n",
      "    %4 = \"mhlo.dot_general\"(%arg0, %3) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<64x64xf32>, tensor<64xf32>) -> tensor<64xf32>\n",
      "    %5 = mhlo.add %4, %arg1 : tensor<64xf32>\n",
      "    %6 = \"mhlo.dot_general\"(%arg0, %5) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<64x64xf32>, tensor<64xf32>) -> tensor<64xf32>\n",
      "    %7 = mhlo.add %6, %arg1 : tensor<64xf32>\n",
      "    %8 = \"mhlo.dot_general\"(%arg0, %7) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<64x64xf32>, tensor<64xf32>) -> tensor<64xf32>\n",
      "    %9 = mhlo.add %8, %arg1 : tensor<64xf32>\n",
      "    %10 = \"mhlo.dot_general\"(%arg0, %9) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<64x64xf32>, tensor<64xf32>) -> tensor<64xf32>\n",
      "    %11 = mhlo.add %10, %arg1 : tensor<64xf32>\n",
      "    %12 = \"mhlo.dot_general\"(%arg0, %11) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<64x64xf32>, tensor<64xf32>) -> tensor<64xf32>\n",
      "    %13 = mhlo.add %12, %arg1 : tensor<64xf32>\n",
      "    %14 = \"mhlo.dot_general\"(%arg0, %13) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<64x64xf32>, tensor<64xf32>) -> tensor<64xf32>\n",
      "    %15 = mhlo.add %14, %arg1 : tensor<64xf32>\n",
      "    %16 = \"mhlo.dot_general\"(%arg0, %15) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<64x64xf32>, tensor<64xf32>) -> tensor<64xf32>\n",
      "    %17 = mhlo.add %16, %arg1 : tensor<64xf32>\n",
      "    %18 = \"mhlo.dot_general\"(%arg0, %17) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>, precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]} : (tensor<64x64xf32>, tensor<64xf32>) -> tensor<64xf32>\n",
      "    %19 = mhlo.add %18, %arg1 : tensor<64xf32>\n",
      "    return %19 : tensor<64xf32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jit(rnn_model).lower(theta, xs).as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd8f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit(rnn_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d758b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(theta, x):\n",
    "    \"\"\"Computes wx + b on a batch of input x.\"\"\"\n",
    "    w, b = theta\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc9508e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xs = np.random.normal(size=(100,))\n",
    "noise = np.random.normal(scale=0.1, size=(100,))\n",
    "ys = xs * 3 - 1 + noise\n",
    "\n",
    "plt.scatter(xs, ys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12323c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.4975571 ,  1.2424994 ,  1.3435951 ,  0.5117413 ,\n",
       "             -1.0394187 ,  2.4631166 ,  0.16100919, -0.16582906,\n",
       "              2.0965214 ,  0.8592652 ,  0.5559618 , -0.15341556,\n",
       "              1.5302485 ,  0.34030586,  0.24364984, -1.1238167 ,\n",
       "              1.4287266 ,  1.1247541 ,  0.52592134,  2.6288614 ,\n",
       "              0.6961215 ,  1.868677  ,  0.7668657 ,  1.0313972 ,\n",
       "              1.8680458 ,  0.73458874,  2.1895213 ,  2.1620634 ,\n",
       "             -0.25226545,  0.25192803,  1.6315435 ,  0.36177188,\n",
       "              0.645198  ,  0.3846354 , -0.2606349 ,  0.09633374,\n",
       "              2.0146384 ,  1.2065446 ,  2.5755448 ,  0.21103817,\n",
       "             -0.9903326 ,  0.71830124,  1.6137104 ,  2.5951104 ,\n",
       "              1.6259768 ,  1.4387809 ,  0.6915536 ,  0.7464498 ,\n",
       "              0.30334097,  0.6659225 ,  1.708233  ,  2.0350833 ,\n",
       "              0.8331384 ,  2.5650659 , -0.80074346,  0.22773564,\n",
       "              0.9778164 ,  1.4079093 ,  0.9434458 ,  0.7987207 ,\n",
       "              0.6717661 ,  1.6181365 ,  0.7640012 , -0.13604128,\n",
       "              0.18321967,  1.0412488 ,  0.8243661 ,  0.19101924,\n",
       "              0.84137523,  1.6521052 , -1.2680054 ,  0.6686216 ,\n",
       "             -0.9003719 , -0.8197311 ,  1.8645009 ,  2.5624845 ,\n",
       "              0.7245947 ,  2.1501632 ,  0.47701788,  3.5420394 ,\n",
       "              2.5944948 ,  0.86896306,  1.7398582 ,  0.73904294,\n",
       "              0.8696954 ,  1.7449719 , -0.6893339 ,  0.51617724,\n",
       "              0.5737134 ,  2.5795517 ,  1.818601  ,  1.9362845 ,\n",
       "              0.52260274,  0.5859711 ,  1.0482578 ,  0.27328175,\n",
       "              0.7048048 ,  1.6988182 ,  1.387775  ,  2.4674244 ],            dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = jnp.array([1., 1.])\n",
    "model(theta, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3981740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(theta, x, y):\n",
    "    prediction = model(theta, x)\n",
    "    return jnp.mean((prediction-y)**2)\n",
    "\n",
    "@jit\n",
    "def update(theta, x, y, lr=0.1):\n",
    "    return theta - lr * grad(loss_fn)(theta, x, y)\n",
    "\n",
    "def train(theta, x, y, lr=0.1):\n",
    "    for _ in range(100):\n",
    "        theta = update(theta, x, y, lr)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b1d772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.67 s, sys: 15.8 ms, total: 6.69 s\n",
      "Wall time: 6.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(1000):\n",
    "    theta = update(theta, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "855e8dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.7 ms, sys: 3.79 ms, total: 40.5 ms\n",
      "Wall time: 39 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([1.3921113, 0.5853443], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "update(theta, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e6fb289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 783 µs, sys: 0 ns, total: 783 µs\n",
      "Wall time: 568 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    update(theta, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67de4115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module @jit_update.31 {\n",
      "  func.func public @main(%arg0: tensor<2xf32>, %arg1: tensor<100xf32>, %arg2: tensor<100xf32>) -> tensor<2xf32> {\n",
      "    %0 = \"mhlo.slice\"(%arg0) {limit_indices = dense<1> : tensor<1xi64>, start_indices = dense<0> : tensor<1xi64>, strides = dense<1> : tensor<1xi64>} : (tensor<2xf32>) -> tensor<1xf32>\n",
      "    %1 = \"mhlo.reshape\"(%0) : (tensor<1xf32>) -> tensor<f32>\n",
      "    %2 = \"mhlo.slice\"(%arg0) {limit_indices = dense<2> : tensor<1xi64>, start_indices = dense<1> : tensor<1xi64>, strides = dense<1> : tensor<1xi64>} : (tensor<2xf32>) -> tensor<1xf32>\n",
      "    %3 = \"mhlo.reshape\"(%2) : (tensor<1xf32>) -> tensor<f32>\n",
      "    %4 = \"mhlo.broadcast_in_dim\"(%1) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<100xf32>\n",
      "    %5 = mhlo.multiply %4, %arg1 : tensor<100xf32>\n",
      "    %6 = \"mhlo.broadcast_in_dim\"(%3) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<100xf32>\n",
      "    %7 = mhlo.add %5, %6 : tensor<100xf32>\n",
      "    %8 = mhlo.subtract %7, %arg2 : tensor<100xf32>\n",
      "    %9 = mhlo.multiply %8, %8 : tensor<100xf32>\n",
      "    %10 = mhlo.constant dense<2.000000e+00> : tensor<f32>\n",
      "    %11 = \"mhlo.broadcast_in_dim\"(%10) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<100xf32>\n",
      "    %12 = mhlo.multiply %11, %8 : tensor<100xf32>\n",
      "    %13 = mhlo.constant dense<0.000000e+00> : tensor<f32>\n",
      "    %14 = mhlo.reduce(%9 init: %13) across dimensions = [0] : (tensor<100xf32>, tensor<f32>) -> tensor<f32>\n",
      "     reducer(%arg3: tensor<f32>, %arg4: tensor<f32>)  {\n",
      "      %38 = mhlo.add %arg3, %arg4 : tensor<f32>\n",
      "      \"mhlo.return\"(%38) : (tensor<f32>) -> ()\n",
      "    }\n",
      "    %15 = mhlo.constant dense<1.000000e+02> : tensor<f32>\n",
      "    %16 = mhlo.divide %14, %15 : tensor<f32>\n",
      "    %17 = mhlo.constant dense<1.000000e+00> : tensor<f32>\n",
      "    %18 = mhlo.constant dense<1.000000e+02> : tensor<f32>\n",
      "    %19 = mhlo.divide %17, %18 : tensor<f32>\n",
      "    %20 = \"mhlo.broadcast_in_dim\"(%19) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<100xf32>\n",
      "    %21 = mhlo.multiply %20, %12 : tensor<100xf32>\n",
      "    %22 = mhlo.constant dense<0.000000e+00> : tensor<f32>\n",
      "    %23 = mhlo.reduce(%21 init: %22) across dimensions = [0] : (tensor<100xf32>, tensor<f32>) -> tensor<f32>\n",
      "     reducer(%arg3: tensor<f32>, %arg4: tensor<f32>)  {\n",
      "      %38 = mhlo.add %arg3, %arg4 : tensor<f32>\n",
      "      \"mhlo.return\"(%38) : (tensor<f32>) -> ()\n",
      "    }\n",
      "    %24 = \"mhlo.broadcast_in_dim\"(%23) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<1xf32>\n",
      "    %25 = mhlo.constant dense<0.000000e+00> : tensor<f32>\n",
      "    %26 = \"mhlo.pad\"(%24, %25) {edge_padding_high = dense<0> : tensor<1xi64>, edge_padding_low = dense<1> : tensor<1xi64>, interior_padding = dense<0> : tensor<1xi64>} : (tensor<1xf32>, tensor<f32>) -> tensor<2xf32>\n",
      "    %27 = mhlo.multiply %21, %arg1 : tensor<100xf32>\n",
      "    %28 = mhlo.constant dense<0.000000e+00> : tensor<f32>\n",
      "    %29 = mhlo.reduce(%27 init: %28) across dimensions = [0] : (tensor<100xf32>, tensor<f32>) -> tensor<f32>\n",
      "     reducer(%arg3: tensor<f32>, %arg4: tensor<f32>)  {\n",
      "      %38 = mhlo.add %arg3, %arg4 : tensor<f32>\n",
      "      \"mhlo.return\"(%38) : (tensor<f32>) -> ()\n",
      "    }\n",
      "    %30 = \"mhlo.broadcast_in_dim\"(%29) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<1xf32>\n",
      "    %31 = mhlo.constant dense<0.000000e+00> : tensor<f32>\n",
      "    %32 = \"mhlo.pad\"(%30, %31) {edge_padding_high = dense<1> : tensor<1xi64>, edge_padding_low = dense<0> : tensor<1xi64>, interior_padding = dense<0> : tensor<1xi64>} : (tensor<1xf32>, tensor<f32>) -> tensor<2xf32>\n",
      "    %33 = mhlo.add %26, %32 : tensor<2xf32>\n",
      "    %34 = mhlo.constant dense<1.000000e-01> : tensor<f32>\n",
      "    %35 = \"mhlo.broadcast_in_dim\"(%34) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<2xf32>\n",
      "    %36 = mhlo.multiply %35, %33 : tensor<2xf32>\n",
      "    %37 = mhlo.subtract %arg0, %36 : tensor<2xf32>\n",
      "    return %37 : tensor<2xf32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lowered = update.lower(theta, xs, ys)\n",
    "print(lowered.as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6166d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled = lowered.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1973785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HloModule jit_update.31, entry_computation_layout={(f32[2]{0},f32[100]{0},f32[100]{0})->f32[2]{0}}\n",
      "\n",
      "%region_0.22 (Arg_0.23: f32[], Arg_1.24: f32[]) -> f32[] {\n",
      "  %Arg_0.23 = f32[] parameter(0)\n",
      "  %Arg_1.24 = f32[] parameter(1)\n",
      "  ROOT %add.25 = f32[] add(f32[] %Arg_0.23, f32[] %Arg_1.24), metadata={op_name=\"jit(update)/jit(main)/reduce_sum[axes=(0,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=4}\n",
      "}\n",
      "\n",
      "%region_1.30 (Arg_0.31: f32[], Arg_1.32: f32[]) -> f32[] {\n",
      "  %Arg_0.31 = f32[] parameter(0)\n",
      "  %Arg_1.32 = f32[] parameter(1)\n",
      "  ROOT %add.33 = f32[] add(f32[] %Arg_0.31, f32[] %Arg_1.32), metadata={op_name=\"jit(update)/jit(main)/reduce_sum[axes=(0,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "}\n",
      "\n",
      "%fused_computation (param_0: f32[2], param_1.4: f32[4], param_2.6: f32[4]) -> f32[2] {\n",
      "  %param_0 = f32[2]{0} parameter(0)\n",
      "  %param_2.6 = f32[4]{0} parameter(2)\n",
      "  %constant.2 = f32[] constant(0)\n",
      "  %reduce.3 = f32[] reduce(f32[4]{0} %param_2.6, f32[] %constant.2), dimensions={0}, to_apply=%region_0.22, metadata={op_name=\"jit(update)/jit(main)/reduce_sum[axes=(0,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=4}\n",
      "  %reshape.1 = f32[1]{0} reshape(f32[] %reduce.3), metadata={op_name=\"jit(update)/jit(main)/broadcast_in_dim[shape=(1,) broadcast_dimensions=()]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %pad.1 = f32[2]{0} pad(f32[1]{0} %reshape.1, f32[] %constant.2), padding=1_0, metadata={op_name=\"jit(update)/jit(main)/pad[padding_config=((1, 0, 0),)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %param_1.4 = f32[4]{0} parameter(1)\n",
      "  %reduce.2 = f32[] reduce(f32[4]{0} %param_1.4, f32[] %constant.2), dimensions={0}, to_apply=%region_1.30, metadata={op_name=\"jit(update)/jit(main)/reduce_sum[axes=(0,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %reshape.0 = f32[1]{0} reshape(f32[] %reduce.2), metadata={op_name=\"jit(update)/jit(main)/broadcast_in_dim[shape=(1,) broadcast_dimensions=()]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %pad.0 = f32[2]{0} pad(f32[1]{0} %reshape.0, f32[] %constant.2), padding=0_1, metadata={op_name=\"jit(update)/jit(main)/pad[padding_config=((0, 1, 0),)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %add.0 = f32[2]{0} add(f32[2]{0} %pad.1, f32[2]{0} %pad.0), metadata={op_name=\"jit(update)/jit(main)/add_any\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %constant.1 = f32[] constant(0.1)\n",
      "  %broadcast.1 = f32[2]{0} broadcast(f32[] %constant.1), dimensions={}\n",
      "  %multiply.2 = f32[2]{0} multiply(f32[2]{0} %add.0, f32[2]{0} %broadcast.1), metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1573330193.py\" source_line=7}\n",
      "  ROOT %subtract.0 = f32[2]{0} subtract(f32[2]{0} %param_0, f32[2]{0} %multiply.2), metadata={op_name=\"jit(update)/jit(main)/sub\" source_file=\"/tmp/ipykernel_1033948/1573330193.py\" source_line=7}\n",
      "}\n",
      "\n",
      "%fused_computation.1 (param_0.2: f32[100], param_1.8: f32[100], param_2.11: f32[2]) -> f32[100] {\n",
      "  %param_2.11 = f32[2]{0} parameter(2)\n",
      "  %slice.1 = f32[1]{0} slice(f32[2]{0} %param_2.11), slice={[0:1]}, metadata={op_name=\"jit(update)/jit(main)/slice[start_indices=(0,) limit_indices=(1,) strides=(1,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %reshape.3 = f32[] reshape(f32[1]{0} %slice.1), metadata={op_name=\"jit(update)/jit(main)/squeeze[dimensions=(0,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %broadcast.4 = f32[100]{0} broadcast(f32[] %reshape.3), dimensions={}, metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %param_0.2 = f32[100]{0} parameter(0)\n",
      "  %multiply.5 = f32[100]{0} multiply(f32[100]{0} %broadcast.4, f32[100]{0} %param_0.2), metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %slice.0 = f32[1]{0} slice(f32[2]{0} %param_2.11), slice={[1:2]}, metadata={op_name=\"jit(update)/jit(main)/slice[start_indices=(1,) limit_indices=(2,) strides=(1,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %reshape.2 = f32[] reshape(f32[1]{0} %slice.0), metadata={op_name=\"jit(update)/jit(main)/squeeze[dimensions=(0,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %broadcast.3 = f32[100]{0} broadcast(f32[] %reshape.2), dimensions={}, metadata={op_name=\"jit(update)/jit(main)/add\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=4}\n",
      "  %add.1 = f32[100]{0} add(f32[100]{0} %multiply.5, f32[100]{0} %broadcast.3), metadata={op_name=\"jit(update)/jit(main)/add\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=4}\n",
      "  %param_1.8 = f32[100]{0} parameter(1)\n",
      "  %subtract.1 = f32[100]{0} subtract(f32[100]{0} %add.1, f32[100]{0} %param_1.8), metadata={op_name=\"jit(update)/jit(main)/sub\" source_file=\"/tmp/ipykernel_1033948/1573330193.py\" source_line=2}\n",
      "  %constant.3 = f32[] constant(0.02)\n",
      "  %broadcast.2 = f32[100]{0} broadcast(f32[] %constant.3), dimensions={}, metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1573330193.py\" source_line=3}\n",
      "  %multiply.4 = f32[100]{0} multiply(f32[100]{0} %subtract.1, f32[100]{0} %broadcast.2), metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1573330193.py\" source_line=3}\n",
      "  ROOT %multiply.3 = f32[100]{0} multiply(f32[100]{0} %multiply.4, f32[100]{0} %param_0.2), metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "}\n",
      "\n",
      "%fused_computation.2 (param_0.5: f32[100], param_1.13: f32[2], param_2.17: f32[100]) -> f32[100] {\n",
      "  %param_1.13 = f32[2]{0} parameter(1)\n",
      "  %slice.3 = f32[1]{0} slice(f32[2]{0} %param_1.13), slice={[0:1]}, metadata={op_name=\"jit(update)/jit(main)/slice[start_indices=(0,) limit_indices=(1,) strides=(1,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %reshape.5 = f32[] reshape(f32[1]{0} %slice.3), metadata={op_name=\"jit(update)/jit(main)/squeeze[dimensions=(0,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %broadcast.10 = f32[100]{0} broadcast(f32[] %reshape.5), dimensions={}, metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %param_2.17 = f32[100]{0} parameter(2)\n",
      "  %multiply.7 = f32[100]{0} multiply(f32[100]{0} %broadcast.10, f32[100]{0} %param_2.17), metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %slice.2 = f32[1]{0} slice(f32[2]{0} %param_1.13), slice={[1:2]}, metadata={op_name=\"jit(update)/jit(main)/slice[start_indices=(1,) limit_indices=(2,) strides=(1,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %reshape.4 = f32[] reshape(f32[1]{0} %slice.2), metadata={op_name=\"jit(update)/jit(main)/squeeze[dimensions=(0,)]\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %broadcast.8 = f32[100]{0} broadcast(f32[] %reshape.4), dimensions={}, metadata={op_name=\"jit(update)/jit(main)/add\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=4}\n",
      "  %add.2 = f32[100]{0} add(f32[100]{0} %multiply.7, f32[100]{0} %broadcast.8), metadata={op_name=\"jit(update)/jit(main)/add\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=4}\n",
      "  %param_0.5 = f32[100]{0} parameter(0)\n",
      "  %subtract.2 = f32[100]{0} subtract(f32[100]{0} %add.2, f32[100]{0} %param_0.5), metadata={op_name=\"jit(update)/jit(main)/sub\" source_file=\"/tmp/ipykernel_1033948/1573330193.py\" source_line=2}\n",
      "  %constant.5 = f32[] constant(0.02)\n",
      "  %broadcast.6 = f32[100]{0} broadcast(f32[] %constant.5), dimensions={}, metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1573330193.py\" source_line=3}\n",
      "  ROOT %multiply.6 = f32[100]{0} multiply(f32[100]{0} %subtract.2, f32[100]{0} %broadcast.6), metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1573330193.py\" source_line=3}\n",
      "}\n",
      "\n",
      "ENTRY %main.40 (Arg_0.1: f32[2], Arg_1.2: f32[100], Arg_2.3: f32[100]) -> f32[2] {\n",
      "  %Arg_0.1 = f32[2]{0} parameter(0)\n",
      "  %Arg_1.2 = f32[100]{0} parameter(1)\n",
      "  %Arg_2.3 = f32[100]{0} parameter(2)\n",
      "  %fusion.1 = f32[100]{0} fusion(f32[100]{0} %Arg_1.2, f32[100]{0} %Arg_2.3, f32[2]{0} %Arg_0.1), kind=kLoop, calls=%fused_computation.1, metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1835602308.py\" source_line=3}\n",
      "  %constant.10 = f32[] constant(0)\n",
      "  %reduce-window.1 = f32[4]{0} reduce-window(f32[100]{0} %fusion.1, f32[] %constant.10), window={size=32 stride=32 pad=14_14}, to_apply=%region_1.30\n",
      "  %fusion.2 = f32[100]{0} fusion(f32[100]{0} %Arg_2.3, f32[2]{0} %Arg_0.1, f32[100]{0} %Arg_1.2), kind=kLoop, calls=%fused_computation.2, metadata={op_name=\"jit(update)/jit(main)/mul\" source_file=\"/tmp/ipykernel_1033948/1573330193.py\" source_line=3}\n",
      "  %reduce-window = f32[4]{0} reduce-window(f32[100]{0} %fusion.2, f32[] %constant.10), window={size=32 stride=32 pad=14_14}, to_apply=%region_0.22\n",
      "  ROOT %fusion = f32[2]{0} fusion(f32[2]{0} %Arg_0.1, f32[4]{0} %reduce-window.1, f32[4]{0} %reduce-window), kind=kLoop, calls=%fused_computation, metadata={op_name=\"jit(update)/jit(main)/sub\" source_file=\"/tmp/ipykernel_1033948/1573330193.py\" source_line=7}\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(compiled.as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51abe83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee5ad89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.train(theta, x, y, lr=0.1)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6405d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "216bc578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ lambda ; a:f32[2] b:f32[100] c:f32[100]. let\n",
       "    d:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; e:f32[2] f:f32[100] g:f32[100]. let\n",
       "          h:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] e\n",
       "          i:f32[] = squeeze[dimensions=(0,)] h\n",
       "          j:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] e\n",
       "          k:f32[] = squeeze[dimensions=(0,)] j\n",
       "          l:f32[100] = mul i f\n",
       "          m:f32[100] = add l k\n",
       "          n:f32[100] = sub m g\n",
       "          o:f32[100] = integer_pow[y=2] n\n",
       "          p:f32[100] = integer_pow[y=1] n\n",
       "          q:f32[100] = mul 2.0 p\n",
       "          r:f32[] = reduce_sum[axes=(0,)] o\n",
       "          _:f32[] = div r 100.0\n",
       "          s:f32[] = div 1.0 100.0\n",
       "          t:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] s\n",
       "          u:f32[100] = mul t q\n",
       "          v:f32[] = reduce_sum[axes=(0,)] u\n",
       "          w:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] v\n",
       "          x:f32[2] = pad[padding_config=((1, 0, 0),)] w 0.0\n",
       "          y:f32[100] = mul u f\n",
       "          z:f32[] = reduce_sum[axes=(0,)] y\n",
       "          ba:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] z\n",
       "          bb:f32[2] = pad[padding_config=((0, 1, 0),)] ba 0.0\n",
       "          bc:f32[2] = add_any x bb\n",
       "          bd:f32[2] = mul 0.10000000149011612 bc\n",
       "          be:f32[2] = sub e bd\n",
       "        in (be,) }\n",
       "      name=update\n",
       "    ] a b c\n",
       "  in (d,) }"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.make_jaxpr(update)(theta, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "723392c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ lambda ; a:f32[2] b:f32[100] c:f32[100]. let\n",
       "    d:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; e:f32[2] f:f32[100] g:f32[100] h:f32[]. let\n",
       "          i:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] e\n",
       "          j:f32[] = squeeze[dimensions=(0,)] i\n",
       "          k:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] e\n",
       "          l:f32[] = squeeze[dimensions=(0,)] k\n",
       "          m:f32[100] = mul j f\n",
       "          n:f32[100] = add m l\n",
       "          o:f32[100] = sub n g\n",
       "          p:f32[100] = integer_pow[y=2] o\n",
       "          q:f32[100] = integer_pow[y=1] o\n",
       "          r:f32[100] = mul 2.0 q\n",
       "          s:f32[] = reduce_sum[axes=(0,)] p\n",
       "          _:f32[] = div s 100.0\n",
       "          t:f32[] = div 1.0 100.0\n",
       "          u:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] t\n",
       "          v:f32[100] = mul u r\n",
       "          w:f32[] = reduce_sum[axes=(0,)] v\n",
       "          x:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] w\n",
       "          y:f32[2] = pad[padding_config=((1, 0, 0),)] x 0.0\n",
       "          z:f32[100] = mul v f\n",
       "          ba:f32[] = reduce_sum[axes=(0,)] z\n",
       "          bb:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] ba\n",
       "          bc:f32[2] = pad[padding_config=((0, 1, 0),)] bb 0.0\n",
       "          bd:f32[2] = add_any y bc\n",
       "          be:f32[] = convert_element_type[new_dtype=float32 weak_type=False] h\n",
       "          bf:f32[2] = mul be bd\n",
       "          bg:f32[2] = sub e bf\n",
       "        in (bg,) }\n",
       "      name=update\n",
       "    ] a b c 0.1\n",
       "    bh:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; bi:f32[2] bj:f32[100] bk:f32[100] bl:f32[]. let\n",
       "          bm:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] bi\n",
       "          bn:f32[] = squeeze[dimensions=(0,)] bm\n",
       "          bo:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] bi\n",
       "          bp:f32[] = squeeze[dimensions=(0,)] bo\n",
       "          bq:f32[100] = mul bn bj\n",
       "          br:f32[100] = add bq bp\n",
       "          bs:f32[100] = sub br bk\n",
       "          bt:f32[100] = integer_pow[y=2] bs\n",
       "          bu:f32[100] = integer_pow[y=1] bs\n",
       "          bv:f32[100] = mul 2.0 bu\n",
       "          bw:f32[] = reduce_sum[axes=(0,)] bt\n",
       "          _:f32[] = div bw 100.0\n",
       "          bx:f32[] = div 1.0 100.0\n",
       "          by:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] bx\n",
       "          bz:f32[100] = mul by bv\n",
       "          ca:f32[] = reduce_sum[axes=(0,)] bz\n",
       "          cb:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] ca\n",
       "          cc:f32[2] = pad[padding_config=((1, 0, 0),)] cb 0.0\n",
       "          cd:f32[100] = mul bz bj\n",
       "          ce:f32[] = reduce_sum[axes=(0,)] cd\n",
       "          cf:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] ce\n",
       "          cg:f32[2] = pad[padding_config=((0, 1, 0),)] cf 0.0\n",
       "          ch:f32[2] = add_any cc cg\n",
       "          ci:f32[] = convert_element_type[new_dtype=float32 weak_type=False] bl\n",
       "          cj:f32[2] = mul ci ch\n",
       "          ck:f32[2] = sub bi cj\n",
       "        in (ck,) }\n",
       "      name=update\n",
       "    ] d b c 0.1\n",
       "    cl:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; cm:f32[2] cn:f32[100] co:f32[100] cp:f32[]. let\n",
       "          cq:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] cm\n",
       "          cr:f32[] = squeeze[dimensions=(0,)] cq\n",
       "          cs:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] cm\n",
       "          ct:f32[] = squeeze[dimensions=(0,)] cs\n",
       "          cu:f32[100] = mul cr cn\n",
       "          cv:f32[100] = add cu ct\n",
       "          cw:f32[100] = sub cv co\n",
       "          cx:f32[100] = integer_pow[y=2] cw\n",
       "          cy:f32[100] = integer_pow[y=1] cw\n",
       "          cz:f32[100] = mul 2.0 cy\n",
       "          da:f32[] = reduce_sum[axes=(0,)] cx\n",
       "          _:f32[] = div da 100.0\n",
       "          db:f32[] = div 1.0 100.0\n",
       "          dc:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] db\n",
       "          dd:f32[100] = mul dc cz\n",
       "          de:f32[] = reduce_sum[axes=(0,)] dd\n",
       "          df:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] de\n",
       "          dg:f32[2] = pad[padding_config=((1, 0, 0),)] df 0.0\n",
       "          dh:f32[100] = mul dd cn\n",
       "          di:f32[] = reduce_sum[axes=(0,)] dh\n",
       "          dj:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] di\n",
       "          dk:f32[2] = pad[padding_config=((0, 1, 0),)] dj 0.0\n",
       "          dl:f32[2] = add_any dg dk\n",
       "          dm:f32[] = convert_element_type[new_dtype=float32 weak_type=False] cp\n",
       "          dn:f32[2] = mul dm dl\n",
       "          do:f32[2] = sub cm dn\n",
       "        in (do,) }\n",
       "      name=update\n",
       "    ] bh b c 0.1\n",
       "    dp:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; dq:f32[2] dr:f32[100] ds:f32[100] dt:f32[]. let\n",
       "          du:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] dq\n",
       "          dv:f32[] = squeeze[dimensions=(0,)] du\n",
       "          dw:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] dq\n",
       "          dx:f32[] = squeeze[dimensions=(0,)] dw\n",
       "          dy:f32[100] = mul dv dr\n",
       "          dz:f32[100] = add dy dx\n",
       "          ea:f32[100] = sub dz ds\n",
       "          eb:f32[100] = integer_pow[y=2] ea\n",
       "          ec:f32[100] = integer_pow[y=1] ea\n",
       "          ed:f32[100] = mul 2.0 ec\n",
       "          ee:f32[] = reduce_sum[axes=(0,)] eb\n",
       "          _:f32[] = div ee 100.0\n",
       "          ef:f32[] = div 1.0 100.0\n",
       "          eg:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] ef\n",
       "          eh:f32[100] = mul eg ed\n",
       "          ei:f32[] = reduce_sum[axes=(0,)] eh\n",
       "          ej:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] ei\n",
       "          ek:f32[2] = pad[padding_config=((1, 0, 0),)] ej 0.0\n",
       "          el:f32[100] = mul eh dr\n",
       "          em:f32[] = reduce_sum[axes=(0,)] el\n",
       "          en:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] em\n",
       "          eo:f32[2] = pad[padding_config=((0, 1, 0),)] en 0.0\n",
       "          ep:f32[2] = add_any ek eo\n",
       "          eq:f32[] = convert_element_type[new_dtype=float32 weak_type=False] dt\n",
       "          er:f32[2] = mul eq ep\n",
       "          es:f32[2] = sub dq er\n",
       "        in (es,) }\n",
       "      name=update\n",
       "    ] cl b c 0.1\n",
       "    et:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; eu:f32[2] ev:f32[100] ew:f32[100] ex:f32[]. let\n",
       "          ey:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] eu\n",
       "          ez:f32[] = squeeze[dimensions=(0,)] ey\n",
       "          fa:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] eu\n",
       "          fb:f32[] = squeeze[dimensions=(0,)] fa\n",
       "          fc:f32[100] = mul ez ev\n",
       "          fd:f32[100] = add fc fb\n",
       "          fe:f32[100] = sub fd ew\n",
       "          ff:f32[100] = integer_pow[y=2] fe\n",
       "          fg:f32[100] = integer_pow[y=1] fe\n",
       "          fh:f32[100] = mul 2.0 fg\n",
       "          fi:f32[] = reduce_sum[axes=(0,)] ff\n",
       "          _:f32[] = div fi 100.0\n",
       "          fj:f32[] = div 1.0 100.0\n",
       "          fk:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] fj\n",
       "          fl:f32[100] = mul fk fh\n",
       "          fm:f32[] = reduce_sum[axes=(0,)] fl\n",
       "          fn:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] fm\n",
       "          fo:f32[2] = pad[padding_config=((1, 0, 0),)] fn 0.0\n",
       "          fp:f32[100] = mul fl ev\n",
       "          fq:f32[] = reduce_sum[axes=(0,)] fp\n",
       "          fr:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] fq\n",
       "          fs:f32[2] = pad[padding_config=((0, 1, 0),)] fr 0.0\n",
       "          ft:f32[2] = add_any fo fs\n",
       "          fu:f32[] = convert_element_type[new_dtype=float32 weak_type=False] ex\n",
       "          fv:f32[2] = mul fu ft\n",
       "          fw:f32[2] = sub eu fv\n",
       "        in (fw,) }\n",
       "      name=update\n",
       "    ] dp b c 0.1\n",
       "    fx:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; fy:f32[2] fz:f32[100] ga:f32[100] gb:f32[]. let\n",
       "          gc:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] fy\n",
       "          gd:f32[] = squeeze[dimensions=(0,)] gc\n",
       "          ge:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] fy\n",
       "          gf:f32[] = squeeze[dimensions=(0,)] ge\n",
       "          gg:f32[100] = mul gd fz\n",
       "          gh:f32[100] = add gg gf\n",
       "          gi:f32[100] = sub gh ga\n",
       "          gj:f32[100] = integer_pow[y=2] gi\n",
       "          gk:f32[100] = integer_pow[y=1] gi\n",
       "          gl:f32[100] = mul 2.0 gk\n",
       "          gm:f32[] = reduce_sum[axes=(0,)] gj\n",
       "          _:f32[] = div gm 100.0\n",
       "          gn:f32[] = div 1.0 100.0\n",
       "          go:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] gn\n",
       "          gp:f32[100] = mul go gl\n",
       "          gq:f32[] = reduce_sum[axes=(0,)] gp\n",
       "          gr:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] gq\n",
       "          gs:f32[2] = pad[padding_config=((1, 0, 0),)] gr 0.0\n",
       "          gt:f32[100] = mul gp fz\n",
       "          gu:f32[] = reduce_sum[axes=(0,)] gt\n",
       "          gv:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] gu\n",
       "          gw:f32[2] = pad[padding_config=((0, 1, 0),)] gv 0.0\n",
       "          gx:f32[2] = add_any gs gw\n",
       "          gy:f32[] = convert_element_type[new_dtype=float32 weak_type=False] gb\n",
       "          gz:f32[2] = mul gy gx\n",
       "          ha:f32[2] = sub fy gz\n",
       "        in (ha,) }\n",
       "      name=update\n",
       "    ] et b c 0.1\n",
       "    hb:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; hc:f32[2] hd:f32[100] he:f32[100] hf:f32[]. let\n",
       "          hg:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] hc\n",
       "          hh:f32[] = squeeze[dimensions=(0,)] hg\n",
       "          hi:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] hc\n",
       "          hj:f32[] = squeeze[dimensions=(0,)] hi\n",
       "          hk:f32[100] = mul hh hd\n",
       "          hl:f32[100] = add hk hj\n",
       "          hm:f32[100] = sub hl he\n",
       "          hn:f32[100] = integer_pow[y=2] hm\n",
       "          ho:f32[100] = integer_pow[y=1] hm\n",
       "          hp:f32[100] = mul 2.0 ho\n",
       "          hq:f32[] = reduce_sum[axes=(0,)] hn\n",
       "          _:f32[] = div hq 100.0\n",
       "          hr:f32[] = div 1.0 100.0\n",
       "          hs:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] hr\n",
       "          ht:f32[100] = mul hs hp\n",
       "          hu:f32[] = reduce_sum[axes=(0,)] ht\n",
       "          hv:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] hu\n",
       "          hw:f32[2] = pad[padding_config=((1, 0, 0),)] hv 0.0\n",
       "          hx:f32[100] = mul ht hd\n",
       "          hy:f32[] = reduce_sum[axes=(0,)] hx\n",
       "          hz:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] hy\n",
       "          ia:f32[2] = pad[padding_config=((0, 1, 0),)] hz 0.0\n",
       "          ib:f32[2] = add_any hw ia\n",
       "          ic:f32[] = convert_element_type[new_dtype=float32 weak_type=False] hf\n",
       "          id:f32[2] = mul ic ib\n",
       "          ie:f32[2] = sub hc id\n",
       "        in (ie,) }\n",
       "      name=update\n",
       "    ] fx b c 0.1\n",
       "    if:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; ig:f32[2] ih:f32[100] ii:f32[100] ij:f32[]. let\n",
       "          ik:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] ig\n",
       "          il:f32[] = squeeze[dimensions=(0,)] ik\n",
       "          im:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] ig\n",
       "          in:f32[] = squeeze[dimensions=(0,)] im\n",
       "          io:f32[100] = mul il ih\n",
       "          ip:f32[100] = add io in\n",
       "          iq:f32[100] = sub ip ii\n",
       "          ir:f32[100] = integer_pow[y=2] iq\n",
       "          is:f32[100] = integer_pow[y=1] iq\n",
       "          it:f32[100] = mul 2.0 is\n",
       "          iu:f32[] = reduce_sum[axes=(0,)] ir\n",
       "          _:f32[] = div iu 100.0\n",
       "          iv:f32[] = div 1.0 100.0\n",
       "          iw:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] iv\n",
       "          ix:f32[100] = mul iw it\n",
       "          iy:f32[] = reduce_sum[axes=(0,)] ix\n",
       "          iz:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] iy\n",
       "          ja:f32[2] = pad[padding_config=((1, 0, 0),)] iz 0.0\n",
       "          jb:f32[100] = mul ix ih\n",
       "          jc:f32[] = reduce_sum[axes=(0,)] jb\n",
       "          jd:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] jc\n",
       "          je:f32[2] = pad[padding_config=((0, 1, 0),)] jd 0.0\n",
       "          jf:f32[2] = add_any ja je\n",
       "          jg:f32[] = convert_element_type[new_dtype=float32 weak_type=False] ij\n",
       "          jh:f32[2] = mul jg jf\n",
       "          ji:f32[2] = sub ig jh\n",
       "        in (ji,) }\n",
       "      name=update\n",
       "    ] hb b c 0.1\n",
       "    jj:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; jk:f32[2] jl:f32[100] jm:f32[100] jn:f32[]. let\n",
       "          jo:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] jk\n",
       "          jp:f32[] = squeeze[dimensions=(0,)] jo\n",
       "          jq:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] jk\n",
       "          jr:f32[] = squeeze[dimensions=(0,)] jq\n",
       "          js:f32[100] = mul jp jl\n",
       "          jt:f32[100] = add js jr\n",
       "          ju:f32[100] = sub jt jm\n",
       "          jv:f32[100] = integer_pow[y=2] ju\n",
       "          jw:f32[100] = integer_pow[y=1] ju\n",
       "          jx:f32[100] = mul 2.0 jw\n",
       "          jy:f32[] = reduce_sum[axes=(0,)] jv\n",
       "          _:f32[] = div jy 100.0\n",
       "          jz:f32[] = div 1.0 100.0\n",
       "          ka:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] jz\n",
       "          kb:f32[100] = mul ka jx\n",
       "          kc:f32[] = reduce_sum[axes=(0,)] kb\n",
       "          kd:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] kc\n",
       "          ke:f32[2] = pad[padding_config=((1, 0, 0),)] kd 0.0\n",
       "          kf:f32[100] = mul kb jl\n",
       "          kg:f32[] = reduce_sum[axes=(0,)] kf\n",
       "          kh:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] kg\n",
       "          ki:f32[2] = pad[padding_config=((0, 1, 0),)] kh 0.0\n",
       "          kj:f32[2] = add_any ke ki\n",
       "          kk:f32[] = convert_element_type[new_dtype=float32 weak_type=False] jn\n",
       "          kl:f32[2] = mul kk kj\n",
       "          km:f32[2] = sub jk kl\n",
       "        in (km,) }\n",
       "      name=update\n",
       "    ] if b c 0.1\n",
       "    kn:f32[2] = xla_call[\n",
       "      call_jaxpr={ lambda ; ko:f32[2] kp:f32[100] kq:f32[100] kr:f32[]. let\n",
       "          ks:f32[1] = slice[limit_indices=(1,) start_indices=(0,) strides=(1,)] ko\n",
       "          kt:f32[] = squeeze[dimensions=(0,)] ks\n",
       "          ku:f32[1] = slice[limit_indices=(2,) start_indices=(1,) strides=(1,)] ko\n",
       "          kv:f32[] = squeeze[dimensions=(0,)] ku\n",
       "          kw:f32[100] = mul kt kp\n",
       "          kx:f32[100] = add kw kv\n",
       "          ky:f32[100] = sub kx kq\n",
       "          kz:f32[100] = integer_pow[y=2] ky\n",
       "          la:f32[100] = integer_pow[y=1] ky\n",
       "          lb:f32[100] = mul 2.0 la\n",
       "          lc:f32[] = reduce_sum[axes=(0,)] kz\n",
       "          _:f32[] = div lc 100.0\n",
       "          ld:f32[] = div 1.0 100.0\n",
       "          le:f32[100] = broadcast_in_dim[broadcast_dimensions=() shape=(100,)] ld\n",
       "          lf:f32[100] = mul le lb\n",
       "          lg:f32[] = reduce_sum[axes=(0,)] lf\n",
       "          lh:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] lg\n",
       "          li:f32[2] = pad[padding_config=((1, 0, 0),)] lh 0.0\n",
       "          lj:f32[100] = mul lf kp\n",
       "          lk:f32[] = reduce_sum[axes=(0,)] lj\n",
       "          ll:f32[1] = broadcast_in_dim[broadcast_dimensions=() shape=(1,)] lk\n",
       "          lm:f32[2] = pad[padding_config=((0, 1, 0),)] ll 0.0\n",
       "          ln:f32[2] = add_any li lm\n",
       "          lo:f32[] = convert_element_type[new_dtype=float32 weak_type=False] kr\n",
       "          lp:f32[2] = mul lo ln\n",
       "          lq:f32[2] = sub ko lp\n",
       "        in (lq,) }\n",
       "      name=update\n",
       "    ] jj b c 0.1\n",
       "  in (kn,) }"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.make_jaxpr(train)(theta, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304854da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(theta, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77662385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([1.2889748, 0.6643548], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update(theta, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0653f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    theta = update(theta, xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6087986a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: 2.99, b: -1.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(xs, ys)\n",
    "plt.plot(xs, model(theta, xs))\n",
    "\n",
    "w, b = theta\n",
    "print(f\"w: {w:<.2f}, b: {b:<.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
